{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3d1c3f6",
   "metadata": {},
   "source": [
    "Intro \n",
    "\n",
    "Application for a work-study program at the Ecole Simplon\n",
    "\n",
    "\n",
    "Scenario\n",
    "\n",
    "Let's imagine that you're a system administrator working on a new project\n",
    "assist a⸱data engineer, within a digital services SME.\n",
    "\n",
    "Business objective:\n",
    "\n",
    "This project concerns a customer who wants to be able to analyze the dynamics of their sales over time and space in order to improve their strategic decision-making."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4721bbc0",
   "metadata": {},
   "source": [
    "Project Tree Stucture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698f5606",
   "metadata": {},
   "source": [
    "Initial desired tree structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dacd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(filename=\"src/Arborescence-V2.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8363ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path problem: to save time, all files are at the root except the src folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55c7989",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(filename=\"src/Arborescence-V1.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7a34ee",
   "metadata": {},
   "source": [
    "Part 1 : ARCHITECTURAL CONCEPTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816a9a41",
   "metadata": {},
   "source": [
    "I - ARCHITECTURE OF THE 2-SERVICE ENVIRONMENT\n",
    "\n",
    "On GitHub Codespaces, the Linux kernel used is managed by GitHub and is based on a customized Ubuntu image running on Azure virtual machines. It is not possible to modify this kernel directly, as updates are controlled by GitHub.\n",
    "\n",
    "-> 1st service: ScriptRunner (Dockerfile)\n",
    "Python image\n",
    "\n",
    "Docker container\n",
    "Custom script execution\n",
    "\n",
    "-> 2nd service: DataWarehouse - BDD (Docker Compose - note: no Dockerlife because no customization)\n",
    "SQLite3 image\n",
    "\n",
    "Data storage and management in a SQLite3 database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c874e668",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display(Image(filename=\"src/architecture-scheme.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438e2f88",
   "metadata": {},
   "source": [
    "II - Communication inputs and outputs between services, indicating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dbbe51",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename=\"src/services-communication.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6494d1f",
   "metadata": {},
   "source": [
    "PORT\n",
    "\n",
    "SQLite is not a server like MySQL or PostgreSQL.\n",
    "SQLite runs locally (codespace), in a .sqlite or .db file.\n",
    "It does not open any network ports.\n",
    "It can be accessed directly from a Python script, a terminal in the container, etc.\n",
    "So :\n",
    "No need to expose a port with SQLite → everything happens locally, in the container or via shared volumes.\n",
    "\n",
    "NB:\n",
    "Codespace sharing: If an application or service is accessible via a port (for example, a web server on port 8000), it's possible to share via this port."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2305062",
   "metadata": {},
   "source": [
    "Part 2 : ARCHITECTURAL CONCEPTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75b9c17",
   "metadata": {},
   "source": [
    "I- Dockerlife"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1587ca7",
   "metadata": {},
   "source": [
    "Service 1 (S1) : ScriptRunner (Dockerfile) \n",
    "\n",
    "> In terminal Launch Docker container :\n",
    "\n",
    "docker build -t my-python-app .\n",
    "\n",
    "> Once the image has been built: my-python-app \n",
    "Launch a container from this image ( my-python-app ) use the following command to launch the container :\n",
    "\n",
    "docker run -it my-python-app /bin/bash\n",
    "\n",
    "> Run the python script hello-world.py :\n",
    "\n",
    "root@93c5907fe1c7:/app# python hello-world.py\n",
    "Output: hello-world S1\n",
    "\n",
    "I tried but failed to : Automate these 2 commands when opening Codespaces with a : \n",
    "Build the my-python-app image then launch an interactive container (/bin/bash) from this image.\n",
    "> Create .devcontainer folder containing :n Dockerfile and devcontainer.json\n",
    "Codespaces already uses a container as a development environment, built from your Dockerfile. So the container you want to launch with docker run is actually your Codespaces environment itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ceb32d4",
   "metadata": {},
   "source": [
    "II- Docker Compose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71ff738",
   "metadata": {},
   "source": [
    "Launch services\n",
    "\n",
    "1- Start Docker Compose in the terminal\n",
    "\n",
    "docker-compose up --build\n",
    "\n",
    "2 -  To start the service that stores the data, use a Docker image with SQLite3\n",
    "(you can find one on Docker Hub) and make sure that it works when you\n",
    "you launch it locally (for example, you can access the\n",
    "SQLite command line in the container).\n",
    "\n",
    "Code : services:\n",
    "  sqlite-db:\n",
    "    image: nouchka/sqlite3:latest # Uses SQLite3 image\n",
    "    stdin_open: true # Opens an interactive session\n",
    "    tty: true # To keep the session interactive\n",
    "    volumes:\n",
    "      - sqlite-data:/data # Persistent volume for SQLite data\n",
    "\n",
    "3- Launch Docker Compose container :\n",
    "\n",
    "docker-compose up -d sqlite-db \n",
    "(The -d option launches the container in the background)\n",
    "\n",
    "4- Access the Docker Compose container\n",
    "Once the container is running, connect to its terminal with this command :\n",
    "bash\n",
    "\n",
    "docker exec -it project-sqlite-db-1 sh\n",
    "Note:  docker ps command to find NAME db\n",
    "\n",
    "5 - Launch SQLite from the command line\n",
    "Once inside the container, type this command to launch SQLite ((sqlite>):\n",
    "bash\n",
    "sqlite3 /data/test.db\n",
    "\n",
    "\n",
    "6 -  Quit SQLite and the container\n",
    "To quit SQLite, type: .exit\n",
    "\n",
    "To quit the container, simply type: bash exit\n",
    "\n",
    "\n",
    "Note: Docker crashes => codespace relaunch\n",
    "https://docs.docker.com/desktop/setup/install/linux/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6a1cff",
   "metadata": {},
   "source": [
    "Part 3 - PRELIMINARY DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa640794",
   "metadata": {},
   "source": [
    "Part 3 - DATA ANALYZING\n",
    "\n",
    "\n",
    "Problem encountered : \n",
    "- Not enough time to debug my script\n",
    "- Periodicity or real-time import of customer data\n",
    "- Problem: Extract customer csv files\n",
    "- Connect to an API for city/region correspondence\n",
    "- Field name (nomad convention with customer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02564f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(filename=\"src/ERD.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a622ff",
   "metadata": {},
   "source": [
    "Brief instruction : \n",
    "In the “hello-world” script (you can rename it if you like), integrate the logic to create the following\n",
    "create the following elements:\n",
    "a. The database\n",
    "b. Tables \n",
    "\n",
    "*I executed this instruction as a comment in hello-world.py *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668a83c8",
   "metadata": {},
   "source": [
    "I - About de Data\n",
    "\n",
    "- Source Data : \n",
    "The customer has provided you with an extract\n",
    "extract of their 30-day sales dataset and data relating to their Products and Stores distributed in several French cities (Localization).\n",
    "\n",
    "- Local import from user's terminal / Deposit on \n",
    "\n",
    "Too small sample to apply ROOOC methodology\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b87929",
   "metadata": {},
   "source": [
    "II -Relationships between entities :\n",
    "\n",
    "3 tables: Store, Product, Sales\n",
    "Product → Sales :\n",
    "Product.product_id → sales.product_id\n",
    "A product may appear in several sales, but each sale concerns a single product \n",
    "=> Relation 1:N\n",
    "1 : There is only one record in the first table.\n",
    "N: This record can be associated with several records in the second table.\n",
    "\n",
    "Store → Sales :\n",
    "Store.store_id → sales.store_id\n",
    "1:N\n",
    "A store can have several sales, but each sale is made in a single store.\n",
    "\n",
    "Product ↔ Store :\n",
    "M:N via Sales table\n",
    "A product can be sold in several stores, and a store can sell several products. This M:N relationship is managed via the Sales table.\n",
    "\n",
    "M: “Several” records in the first table.\n",
    "N: “Several” records in the second table.\n",
    "Each record in the first table can be linked to several records in the second table, and each record in the second table can be linked to several records in the first table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90d5f05",
   "metadata": {},
   "source": [
    "Relationship summary:\n",
    "1:N: A product can appear in several sales, but each sale concerns a single product. \n",
    "1:N: A store can have several sales, but each sale belongs to a single store.\n",
    "M:N: A product can be sold in several stores, and a store can sell several products, which is managed via the Sales link table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55dab66",
   "metadata": {},
   "source": [
    "III- Data import \n",
    "\n",
    "Method 1 => via ScriptRunner \n",
    "(+) fine granularity (processing, cleansing) , (-) very slow and inefficient on large volumes\n",
    "Method 2 => DataWarehouse direct (csv easy to purge and format in our case beforehand) :\n",
    "(+) Much faster: mass ingestion\n",
    "(-) Possibility of directly connecting BI tools\n",
    "\n",
    "According to Methodology 1 instruction (Q: in our case, considering the business challenges (Sales) a priori M2).\n",
    "\n",
    "Business and workflow issues: periodic or real-time import of customer csvs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef46ae76",
   "metadata": {},
   "source": [
    "IV - Problems encountered : \n",
    "Periodicity or real-time import of customer data\n",
    "Problem: Extract customer csv files\n",
    "Connect to an API for city/region correspondence\n",
    "Field name (nomad convention with customer)\n",
    "\n",
    "\n",
    "a - Rebuiding images \n",
    "\n",
    "After creating sales-analyze.py and not found on app\n",
    "I had to rebuild the app image: \n",
    "\n",
    "docker build -t my-python-app .\n",
    "docker run my-python-app\n",
    "docker run -it my-python-app /bin/bash (bash ls - the file is in the app)\n",
    "\n",
    "I checked on the database Docker whether the bdd had been created correctly \n",
    "\n",
    "docker-compose up --build\n",
    "docker-compose up -d sqlite-db \n",
    "(The -d option launches the container in the background)\n",
    "docker-compose restart script-runner\n",
    "\n",
    "docker exec -it project-sqlite-db-1 sh\n",
    "\n",
    "b - Data cleaning and formatting \n",
    "\n",
    "Problems with inconsistent data or replacement by an average value or Nan or deletion of record line \n",
    "Question: as with R, avoid making loops so you don't have to do it for each df\n",
    "\n",
    "c - Business and workflow issues\n",
    "Periodic or real-time import of customer csvs\n",
    "System load optimization: \n",
    "To avoid excessive power or resource consumption in Docker containers\n",
    "If file is local, use python watchdog library (real-time monitoring of modifications)\n",
    "Use a watchdog in a separate process: in the background or a separate service in Docker (e.g. a cron or a script) to perform the update, instead of continuously polling with a Python script.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91922b0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89779c70",
   "metadata": {},
   "source": [
    "ANALYSE RESULT VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ebd2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas matplotlib seaborn\n",
    "\n",
    "# Import necessary libraries for vizualisation\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c09e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to SQLite database\n",
    "db_name = \"sales-analyze.db\"\n",
    "conn = sqlite3.connect(db_name)\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80c2d2c",
   "metadata": {},
   "source": [
    "Load Result table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381d5b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql_query(\"SELECT * FROM Result\", conn)\n",
    "conn.close()\n",
    "\n",
    "# Data overview\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b815ed",
   "metadata": {},
   "source": [
    " Visualization (a) : Total Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2c12ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_revenue = df[df[\"type\"] == \"total_revenue\"][\"total_revenue\"].sum()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.bar([\"Total Revenue\"], [total_revenue], color=\"green\")\n",
    "plt.title(\"Total Revenue\")\n",
    "plt.ylabel(\"Amount (€)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf46b3e",
   "metadata": {},
   "source": [
    " Visualization (b) : Sales by Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9e36b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_products = df[df[\"type\"] == \"sales_by_product\"]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(df_products[\"product_name\"], df_products[\"total_revenue\"], color=\"skyblue\")\n",
    "plt.title(\"Total Revenue by Product\")\n",
    "plt.xlabel(\"Product\")\n",
    "plt.ylabel(\"Revenue (€)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b154f7",
   "metadata": {},
   "source": [
    " Visualization (c) : Sales by Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7932d619",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regions = df[df[\"type\"] == \"sales_by_region\"]\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=df_regions, x=\"region\", y=\"total_revenue\", palette=\"mako\")\n",
    "plt.title(\"Total Revenue by Region\")\n",
    "plt.xlabel(\"Region\")\n",
    "plt.ylabel(\"Revenue (€)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32075176",
   "metadata": {},
   "source": [
    "APPENDIX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d111a04d",
   "metadata": {},
   "source": [
    "Areas for improvement : \n",
    "\n",
    "\n",
    "- Methods for centralizing sales data\n",
    "(Google Drive, API, Integrator ( Zapier),\n",
    "- Upload customer files via url \n",
    "(Make a utility that checks data loading: only dirty data because (secure Maj change product and stores )\n",
    "- Others services : Visualization, Loading critical files as sales\n",
    "- API data file (cleansing and transformation) - workflow optimization and security \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8d1193",
   "metadata": {},
   "source": [
    "Git Commands:\n",
    "\n",
    "Git COMMIT (qd le faire) pas fait de versioning\n",
    "(Bash - Terminal)\n",
    "git add .\n",
    "git commit -m \n",
    "git push origin main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74543642",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699ea7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to html analyse_ventes.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf84410",
   "metadata": {},
   "source": [
    "Right-click on the .html file → “Download” to open it in your browser."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
